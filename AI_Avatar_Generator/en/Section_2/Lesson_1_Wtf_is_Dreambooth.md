You’re now well-versed with what Stable Diffusion is and how it works. Except it has one big problem - you can’t teach it new things. There’s no way I can give it 10 pictures of my dog and make it generate images of my dog on the bed so I can gaslight him into thinking he broke the rules.

In comes [Dreambooth](https://dreambooth.github.io/) - a machine learning technique that lets you generate photorealistic images of specific subjects in a variety of different contexts. 

Stable Diffusion knows everything about the general world - what clouds look like, how bald Dwayne “The Rock” Johnson is, and what rainbows are made of. Using Dreambooth, you can teach it what ********you******** look like too!

### How do Dreambooth + SD work together?

To use Dreambooth, we’ll have to give it some training data: a set of images of ourselves, or whoever we want to generate images of, along with a label (our name) and the class of objects the thing belongs to (human).

Dreambooth then fine-tunes a pre-trained text-to-image model to learn to recognize and generate images of the specific subject. 

![](https://hackmd.io/_uploads/r10nDpEqi.png)

### How does it work?

Unlike magic, this tech is even cooler when you know the trick. 

We've got the OG Stable Diffusion model. That's not the special part. What's really going to make it ours is the set of input photos we'll use. Here's a simplified flow of how it'll work:

1. The SD model is trained on a dataset of images that represent one subject (you).
2. Using the input photos, the model extracts the key features and characteristics of the faces in the photos.
3. The model uses the extracted features to generate new, synthesized images that resemble the input photos but have their own unique style and variations based on our text.

Soon you’ll be able to turn yourself into Thor (aka Thorza) like I did below

![](https://hackmd.io/_uploads/ryi6v6Ncj.png)

### Training Dreambooth models is a big deal

You know all those fancy AI-style profile pictures you’re seeing on Twitter and Instagram? All of them were generated by fine-tuning SD models using Dreambooth. That’s what Lensa charges $$$ for. All of this is open-source tech that was made available to everyone at the same time, it was all up to the builders to ship fast and get it in front of people. 

While it’s not likely that you’ll be able to make a $50k MRR app overnight by building this out, you’ll know how it works and you’ll be ready to capture the opportunity the next time it arises!

## Training Dreambooth models on yourself

### Getting tasty photos of yourself

**It is time.** 

The first thing you’ll need to do is gather training data. Since we’re making AI avatars of ourselves, we’ll have to get a bunch of pictures. For your first run, I recommend going with 5-10 images. These can’t just be your average selfies though, we have to be very careful with what we teach the AI.

Here’s a few rules for your pics:

1. **Pictures should contain only you** - no friends, dogs, samosas, aunties
2. **Clear backgrounds -** If you can’t get white backgrounds, use [https://remove.bg/](https://remove.bg/) to remove them entirely
3. **Picture quality** - Pictures should be well lit
4. **Picture size** - At least 720p at the minimum. You ************can************ use laptop webcams but you need to be in a well-lit place lol

You gotta be careful here - more images do ********not******** mean better results! For my first set I used 19 pics and it came out pretty meh. The big mistake I made was using a blue background in ************every************ picture. I taught SD that I always have a blue background, so it generated results with blue backgrounds!

![](https://hackmd.io/_uploads/H1hAD6Ncj.png)

Let’s take some pics!! Grab your phone, webcam, DSLR — whatever you got and get snappin. Your pictures should show off features that you want SD to learn about. Maybe you tighten your jawline or get a Zac Efron haircut. Up to you lol. Check out the pics I took below:

![](https://hackmd.io/_uploads/rJxzOpEqo.png)

Once you’ve got all your pics and are happy with the backgrounds, we can prep them for processing. The main thing we need to do here is to resize them to 512x512 because that’s the size of all the images we’ll be generating. Head over to [Birme](https://www.birme.net/?target_width=512&target_height=512) and resize all your pics to 512x512. 

The last thing you need to do is rename all your pics with a unique label. SD has millions of data points for what a “man”, “woman” or “handsome AI developer” looks like. It probably also has lots of results for your first name. So what we need to do here is give you, the subject, a distinct name that we can use in prompts.

I’m mashing my first and last names to get “abraza”. So in a prompt I’d go “Oil paint portrait of **abraza** as a professional wrestler by Vincent Van Gogh”.

Pretty simple eh? You can try a couple of different angles, but make sure they’re close-up pics. Torso pics work too, but keep it above the belt.

Our data is ready! Onwards!

### Training with Google Colab

The main event - **training**. This is where things start to get **REALLY** cool.

Since this is really compute intensive, we’ll need some powerful GPUs for this. Don’t have a beefy GPU? Worry not! Google Colab to the rescue! 

Google Colab is basically just an IDE inside a browser. It’s connected to the Google Cloud Platform so we never have to install any base dependencies and get lots of free compute. Thanks Google!

We’ll be using Python for this part, except you won’t actually have to write any Python or set up a Python environment! This will be done with the magic of Jupyter notebooks.

Checkout this quick TL;DR on Jupyter notebooks on Google Colab:

[https://www.loom.com/share/8fca2d8ef42642d4b5e76ed5279c67d3](https://www.loom.com/share/8fca2d8ef42642d4b5e76ed5279c67d3)

We ****can**** use Jupyter notebooks in VS Code, but we’ll be using Google Colab cause we get free compute! Who can say no to a free Tesla T4 GPU?  

Colab notebooks can be shared like files, so I’ll just give you a link that you can copy over to your Google Drive. 

Let’s goooooo!